{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "train_df = pd.read_csv(Path('Resources/Generator/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/Generator/2020Q1loans.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "train_x = train_df.drop(columns='target')\n",
    "train_x = pd.get_dummies(train_x)\n",
    "train_y = train_df['target']\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "train_y = label_enc.fit_transform(train_y)\n",
    "\n",
    "# add missing dummy variables to testing set\n",
    "test_x = test_df.drop(columns='target')\n",
    "test_x = pd.get_dummies(test_x)\n",
    "test_y = test_df['target']\n",
    "test_y = label_enc.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12180, 92)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4702, 91)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['debt_settlement_flag_Y']\n"
     ]
    }
   ],
   "source": [
    "matching_columns = []\n",
    "for item in train_x.columns:\n",
    "    if item in test_x.columns:\n",
    "        pass\n",
    "    else:\n",
    "        matching_columns.append(item)\n",
    "print(matching_columns)\n",
    "\n",
    "train_x = train_x.drop(columns='debt_settlement_flag_Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7017241379310345\n",
      "Testing Socre: 0.5650786899191833\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=200000)\n",
    "clf.fit(train_x, train_y)\n",
    "print(f'Training Score: {clf.score(train_x, train_y)}')\n",
    "print(f'Testing Socre: {clf.score(test_x, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Socre: 0.6393024245002127\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2.fit(train_x, train_y)\n",
    "print(f'Training Score: {clf2.score(train_x, train_y)}')\n",
    "print(f'Testing Socre: {clf2.score(test_x, test_y)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_x)\n",
    "X_test_scaled = scaler.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7108374384236453\n",
      "Testing Socre: 0.6586558911101659\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=200000)\n",
    "clf.fit(X_train_scaled, train_y)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, train_y)}')\n",
    "print(f'Testing Socre: {clf.score(X_test_scaled, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7108374384236453\n",
      "Testing Score: 0.6586558911101659\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf3 = RandomForestClassifier()\n",
    "clf3.fit(X_train_scaled, train_y)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, train_y)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1: last_pymnt_amnt - Importance: 0.1028\n",
      "Feature 2: total_rec_prncp - Importance: 0.0548\n",
      "Feature 3: total_pymnt - Importance: 0.0468\n",
      "Feature 4: total_rec_int - Importance: 0.0466\n",
      "Feature 5: total_pymnt_inv - Importance: 0.0454\n",
      "Feature 6: int_rate - Importance: 0.0342\n",
      "Feature 7: installment - Importance: 0.0308\n",
      "Feature 8: out_prncp_inv - Importance: 0.0307\n",
      "Feature 9: out_prncp - Importance: 0.0285\n",
      "Feature 10: loan_amnt - Importance: 0.0167\n",
      "Feature 11: mo_sin_old_rev_tl_op - Importance: 0.0166\n",
      "Feature 12: total_rec_late_fee - Importance: 0.0166\n",
      "Feature 13: max_bal_bc - Importance: 0.0158\n",
      "Feature 14: dti - Importance: 0.0155\n",
      "Feature 15: total_rev_hi_lim - Importance: 0.0154\n",
      "Feature 16: total_bc_limit - Importance: 0.0153\n",
      "Feature 17: bc_open_to_buy - Importance: 0.0153\n",
      "Feature 18: revol_bal - Importance: 0.0151\n",
      "Feature 19: mo_sin_old_il_acct - Importance: 0.0149\n",
      "Feature 20: tot_hi_cred_lim - Importance: 0.0145\n",
      "Feature 21: annual_inc - Importance: 0.0144\n",
      "Feature 22: avg_cur_bal - Importance: 0.0143\n",
      "Feature 23: bc_util - Importance: 0.0141\n",
      "Feature 24: il_util - Importance: 0.0139\n",
      "Feature 25: total_bal_il - Importance: 0.0135\n",
      "Feature 26: total_il_high_credit_limit - Importance: 0.0132\n",
      "Feature 27: tot_cur_bal - Importance: 0.0130\n",
      "Feature 28: total_bal_ex_mort - Importance: 0.0128\n",
      "Feature 29: all_util - Importance: 0.0127\n",
      "Feature 30: mths_since_recent_bc - Importance: 0.0126\n",
      "Feature 31: mths_since_rcnt_il - Importance: 0.0121\n",
      "Feature 32: mo_sin_rcnt_rev_tl_op - Importance: 0.0121\n",
      "Feature 33: total_acc - Importance: 0.0118\n",
      "Feature 34: mths_since_recent_inq - Importance: 0.0117\n",
      "Feature 35: acc_open_past_24mths - Importance: 0.0104\n",
      "Feature 36: mo_sin_rcnt_tl - Importance: 0.0101\n",
      "Feature 37: num_il_tl - Importance: 0.0100\n",
      "Feature 38: num_rev_accts - Importance: 0.0095\n",
      "Feature 39: pct_tl_nvr_dlq - Importance: 0.0095\n",
      "Feature 40: open_acc - Importance: 0.0087\n",
      "Feature 41: num_bc_tl - Importance: 0.0085\n",
      "Feature 42: num_sats - Importance: 0.0083\n",
      "Feature 43: num_actv_rev_tl - Importance: 0.0081\n",
      "Feature 44: num_op_rev_tl - Importance: 0.0080\n",
      "Feature 45: num_rev_tl_bal_gt_0 - Importance: 0.0076\n",
      "Feature 46: open_rv_24m - Importance: 0.0076\n",
      "Feature 47: inq_last_12m - Importance: 0.0075\n",
      "Feature 48: percent_bc_gt_75 - Importance: 0.0073\n",
      "Feature 49: num_bc_sats - Importance: 0.0071\n",
      "Feature 50: num_tl_op_past_12m - Importance: 0.0071\n",
      "Feature 51: num_actv_bc_tl - Importance: 0.0068\n",
      "Feature 52: total_cu_tl - Importance: 0.0066\n",
      "Feature 53: open_act_il - Importance: 0.0064\n",
      "Feature 54: open_il_24m - Importance: 0.0059\n",
      "Feature 55: inq_fi - Importance: 0.0059\n",
      "Feature 56: mort_acc - Importance: 0.0056\n",
      "Feature 57: open_rv_12m - Importance: 0.0045\n",
      "Feature 58: tot_coll_amt - Importance: 0.0045\n",
      "Feature 59: inq_last_6mths - Importance: 0.0043\n",
      "Feature 60: open_acc_6m - Importance: 0.0043\n",
      "Feature 61: num_accts_ever_120_pd - Importance: 0.0037\n",
      "Feature 62: open_il_12m - Importance: 0.0037\n",
      "Feature 63: delinq_2yrs - Importance: 0.0031\n",
      "Feature 64: hardship_flag_N - Importance: 0.0026\n",
      "Feature 65: hardship_flag_Y - Importance: 0.0021\n",
      "Feature 66: verification_status_Not Verified - Importance: 0.0021\n",
      "Feature 67: verification_status_Source Verified - Importance: 0.0020\n",
      "Feature 68: home_ownership_MORTGAGE - Importance: 0.0018\n",
      "Feature 69: home_ownership_RENT - Importance: 0.0018\n",
      "Feature 70: home_ownership_OWN - Importance: 0.0015\n",
      "Feature 71: verification_status_Verified - Importance: 0.0015\n",
      "Feature 72: application_type_Individual - Importance: 0.0014\n",
      "Feature 73: application_type_Joint App - Importance: 0.0014\n",
      "Feature 74: pub_rec_bankruptcies - Importance: 0.0014\n",
      "Feature 75: pub_rec - Importance: 0.0013\n",
      "Feature 76: initial_list_status_w - Importance: 0.0011\n",
      "Feature 77: initial_list_status_f - Importance: 0.0010\n",
      "Feature 78: num_tl_90g_dpd_24m - Importance: 0.0010\n",
      "Feature 79: collections_12_mths_ex_med - Importance: 0.0007\n",
      "Feature 80: chargeoff_within_12_mths - Importance: 0.0003\n",
      "Feature 81: home_ownership_ANY - Importance: 0.0002\n",
      "Feature 82: debt_settlement_flag_N - Importance: 0.0001\n",
      "Feature 83: recoveries - Importance: 0.0000\n",
      "Feature 84: collection_recovery_fee - Importance: 0.0000\n",
      "Feature 85: policy_code - Importance: 0.0000\n",
      "Feature 86: acc_now_delinq - Importance: 0.0000\n",
      "Feature 87: delinq_amnt - Importance: 0.0000\n",
      "Feature 88: num_tl_120dpd_2m - Importance: 0.0000\n",
      "Feature 89: num_tl_30dpd - Importance: 0.0000\n",
      "Feature 90: tax_liens - Importance: 0.0000\n",
      "Feature 91: pymnt_plan_n - Importance: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# use the feature importance function to identify importance features\n",
    "# sort them from highest to lowest\n",
    "features = clf3.feature_importances_\n",
    "indices = np.argsort(features)[::-1]\n",
    "for i, feature_idx in enumerate(indices):\n",
    "    feature_name = train_x.columns[feature_idx]  # Replace with appropriate feature names if using pandas DataFrame\n",
    "    importance = features[feature_idx]\n",
    "    print(f\"Feature {i+1}: {feature_name} - Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Training Score: 0.6547619047619048\n",
      "Log Testing Score: 0.5284985112717993\n",
      "----------\n",
      "RFC Training Score: 0.6547619047619048\n",
      "RFC Testing Score: 0.5284985112717993\n"
     ]
    }
   ],
   "source": [
    "# select threshold parameter\n",
    "threshold = .04\n",
    "\n",
    "# Select the important features\n",
    "sel = SelectFromModel(clf3, threshold=threshold)\n",
    "sel.fit(X_train_scaled, train_y)\n",
    "\n",
    "# prints the values that are important\n",
    "# sel.get_support()\n",
    "\n",
    "# train with selected features\n",
    "train_selected = sel.transform(X_train_scaled)\n",
    "test_selected = sel.transform(X_test_scaled)\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=200000)\n",
    "clf.fit(train_selected, train_y)\n",
    "print(f'Log Training Score: {clf.score(train_selected, train_y)}')\n",
    "print(f'Log Testing Score: {clf.score(test_selected, test_y)}')\n",
    "\n",
    "print(\"-\"*30)\n",
    "# Random Forest Classifer\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2.fit(train_selected, train_y)\n",
    "print(f'RFC Training Score: {clf.score(train_selected, train_y)}')\n",
    "print(f'RFC Testing Score: {clf.score(test_selected, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "708be08e11aab052d163876fb7e5f0950b68df23e3ca93fef65e76b7852dc274"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
